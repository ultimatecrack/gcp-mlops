{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab11344-8571-4834-b50f-49b935d34370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Input,Output,Metrics,component,Model)\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f519082-d024-469b-8a9c-8bd84e9fa448",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "packages_to_install=[\"gcsfs\",\"pandas\",\"google-cloud-storage\"]\n",
    ")\n",
    "def validate_input_ds(filename:str)-> NamedTuple(\"output\", [(\"input_validation\", str)]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import pandas as pd\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logging.info(f\"Reading file: {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    expected_num_cols = 26\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    logging.info(f\"Number of columns: {num_cols}\")\n",
    "    \n",
    "    input_validation=\"true\"\n",
    "    \n",
    "    if num_cols != expected_num_cols:\n",
    "        input_validation=\"false\"\n",
    "        \n",
    "    expected_col_names = ['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
    "                               'expiration', 'gender', 'age', 'maritalStatus', 'has_children',\n",
    "                               'education', 'occupation', 'income', 'car', 'Bar', 'CoffeeHouse',\n",
    "                               'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50',\n",
    "                               'toCoupon_GEQ5min', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min',\n",
    "                               'direction_same', 'direction_opp', 'Y']\n",
    "\n",
    "    if set(df.columns) != set(expected_col_names):\n",
    "        input_validation=\"false\"\n",
    "\n",
    "    return (input_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "633d7bc3-3348-41e1-a8db-3a78f7a5c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "packages_to_install=[\"google-cloud-aiplatform\",\"gcsfs\",\"xgboost\",\"category_encoders\",\"imblearn\",\"pandas\",\"google-cloud-storage\"]\n",
    ")\n",
    "def custom_training_job_component(\n",
    "    max_depth:int,\n",
    "    learning_rate:float,\n",
    "    n_estimators:int,\n",
    "    metrics: Output[Metrics]\n",
    ")->NamedTuple(\"output\", [(\"model_validation\", str)]):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from category_encoders import HashingEncoder\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from xgboost import XGBClassifier\n",
    "    from google.cloud import storage\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(\"sid-kubeflow-v1\")\n",
    "\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(df):\n",
    "\n",
    "        df = df.drop(columns=['car', 'toCoupon_GEQ5min', 'direction_opp'])\n",
    "        df = df.fillna(df.mode().iloc[0])\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df_dummy = df.copy()\n",
    "        age_list = []\n",
    "        for i in df['age']:\n",
    "            if i == 'below21':\n",
    "                age = '<21'\n",
    "            elif i in ['21', '26']:\n",
    "                age = '21-30'\n",
    "            elif i in ['31', '36']:\n",
    "                age = '31-40'\n",
    "            elif i in ['41', '46']:\n",
    "                age = '41-50'\n",
    "            else:\n",
    "                age = '>50'\n",
    "            age_list.append(age)\n",
    "        df_dummy['age'] = age_list\n",
    "\n",
    "        df_dummy['passanger_destination'] = df_dummy['passanger'].astype(str) + '-' + df_dummy['destination'].astype(str)\n",
    "        df_dummy['marital_hasChildren'] = df_dummy['maritalStatus'].astype(str) + '-' + df_dummy['has_children'].astype(str)\n",
    "        df_dummy['temperature_weather'] = df_dummy['temperature'].astype(str) + '-' + df_dummy['weather'].astype(str)\n",
    "        df_dummy = df_dummy.drop(columns=['passanger', 'destination', 'maritalStatus', 'has_children', 'temperature','weather', 'Y'])\n",
    "\n",
    "        df_dummy = pd.concat([df_dummy, df['Y']], axis = 1)\n",
    "        df_dummy = df_dummy.drop(columns=['gender', 'RestaurantLessThan20'])\n",
    "        df_le = df_dummy.replace({\n",
    "            'expiration':{'2h': 0, '1d' : 1},\n",
    "            'age':{'<21': 0, '21-30': 1, '31-40': 2, '41-50': 3, '>50': 4},\n",
    "            'education':{'Some High School': 0, 'High School Graduate': 1, 'Some college - no degree': 2,\n",
    "                         'Associates degree': 3, 'Bachelors degree': 4, 'Graduate degree (Masters or Doctorate)': 5},\n",
    "            'Bar':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'CoffeeHouse':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "            'CarryAway':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "            'Restaurant20To50':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'income':{'Less than $12500':0, '$12500 - $24999':1, '$25000 - $37499':2, '$37500 - $49999':3,\n",
    "                      '$50000 - $62499':4, '$62500 - $74999':5, '$75000 - $87499':6, '$87500 - $99999':7,\n",
    "                      '$100000 or More':8},\n",
    "            'time':{'7AM':0, '10AM':1, '2PM':2, '6PM':3, '10PM':4}\n",
    "        })\n",
    "\n",
    "        x = df_le.drop('Y', axis=1)\n",
    "        y = df_le.Y\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def train_model(x_train, y_train,max_depth,learning_rate,n_estimators):\n",
    "        \n",
    "        model = XGBClassifier(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(model, x_test, y_test, x_sm_train_hashing, y_sm_train):\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred_proba = model.predict_proba(x_test)\n",
    "        y_pred_train = model.predict(x_sm_train_hashing)\n",
    "        y_pred_train_proba = model.predict_proba(x_sm_train_hashing)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "\n",
    "        # roc_auc_train_proba = roc_auc_score(y_sm_train, y_pred_train_proba[:, 1])\n",
    "        # roc_auc_test_proba = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "\n",
    "        return accuracy,precision,recall\n",
    "\n",
    "    def encode_features(x, n_components=27):\n",
    "        hashing_ros_enc = HashingEncoder(cols=['passanger_destination', 'marital_hasChildren', 'occupation', 'coupon',\n",
    "                                               'temperature_weather'], n_components=n_components).fit(x)\n",
    "        x_test_hashing = hashing_ros_enc.transform(x.reset_index(drop=True))\n",
    "        return x_test_hashing\n",
    "\n",
    "    def oversample_data(x_train_hashing, y_train):\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_sm_train_hashing, y_sm_train = sm.fit_resample(x_train_hashing, y_train)\n",
    "        return x_sm_train_hashing, y_sm_train\n",
    "\n",
    "    def save_model_artifact(pipeline):\n",
    "        artifact_name = 'model.bst'\n",
    "        pipeline.save_model(artifact_name)\n",
    "        model_artifact = bucket.blob('coupon-recommendation/artifacts/'+artifact_name)\n",
    "        model_artifact.upload_from_filename(artifact_name)\n",
    "\n",
    "    input_file = \"gs://sid-kubeflow-v1/coupon-recommendation/in-vehicle-coupon-recommendation.csv\"\n",
    "    df = load_data(input_file)\n",
    "    x, y = preprocess_data(df)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    x_train.fillna(x_train.mode().iloc[0], inplace=True)\n",
    "    x_test.fillna(x_train.mode().iloc[0], inplace=True)\n",
    "    \n",
    "    model_name = 'xgboost'\n",
    "    print(\"Training and evaluating\", model_name, \"model:\")\n",
    "    x_train_hashing = encode_features(x_train)\n",
    "    x_test_hashing = encode_features(x_test)\n",
    "    x_sm_train_hashing, y_sm_train = oversample_data(x_train_hashing,y_train)\n",
    "\n",
    "    pipeline = train_model(x_sm_train_hashing,y_sm_train,max_depth,learning_rate,n_estimators)\n",
    "\n",
    "    accuracy,precision,recall = evaluate_model(pipeline,x_test_hashing,y_test,x_sm_train_hashing,y_sm_train)\n",
    "    metrics.log_metric(\"accurancy\", accuracy)\n",
    "    metrics.log_metric(\"precision\", precision)\n",
    "    metrics.log_metric(\"recall\", recall)\n",
    "    \n",
    "    model_validation = \"true\"\n",
    "    if accuracy>0.5 and precision>0.5 :\n",
    "        save_model_artifact(pipeline)\n",
    "        model_validation=\"true\"\n",
    "    else :\n",
    "        model_validation=\"false\"\n",
    "\n",
    "    return (model_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f2613-bff4-49ee-bf21-abfb685dd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def model_deployment()-> NamedTuple(\"endpoint\", [(\"endpoint\", str)]):\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    aiplatform.init(project=\"udemy-mlops\", location=\"us-central1\", staging_bucket=\"gs://sid-kubeflow-v1\")\n",
    "    \n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=\"coupon-recommendation-model\",\n",
    "        artifact_uri=\"gs://sid-kubeflow-v1/coupon-recommendation/artifacts/\",\n",
    "        serving_container_image_uri = \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\",\n",
    "        sync=False\n",
    "    )\n",
    "    \n",
    "    DEPLOYED_NAME = \"coupon-model-endpoint\"\n",
    "    TRAFFIC_SPLIT = {\"0\": 100}\n",
    "    MIN_NODES = 1\n",
    "    MAX_NODES = 1\n",
    "\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=\"gs://sid-kubeflow-v1/coupon-pipeline-v1\",\n",
    "    name=\"coupon-model-training-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    project: str = \"udemy-mlops\",\n",
    "    region: str = \"us-central1\"\n",
    "    ):\n",
    "    \n",
    "    max_depth=5\n",
    "    learning_rate=0.2\n",
    "    n_estimators=40\n",
    "    \n",
    "    file_name = \"gs://sid-kubeflow-v1/coupon-recommendation/in-vehicle-coupon-recommendation.csv\"\n",
    "    input_validation_task = validate_input_ds(file_name)\n",
    "    \n",
    "    with dsl.Condition(input_validation_task.outputs[\"input_validation\"] == \"true\"):\n",
    "        model_training = custom_training_job_component(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "        ).after(input_validation_task)\n",
    "        \n",
    "        with dsl.Condition(model_training.outputs[\"model_validation\"] == \"true\"):\n",
    "            task_deploy_model = model_deployment().after(model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e70069",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,package_path='coupon-pipeline-deploy-v1.json')\n",
    "\n",
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"model-deployment-pipeline\",\n",
    "    template_path=\"coupon-pipeline-deploy-v1.json\",\n",
    "    enable_caching=False,\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "start_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
